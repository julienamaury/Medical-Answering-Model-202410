{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 998,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02004008016032064,
      "grad_norm": 0.5433533787727356,
      "learning_rate": 9e-06,
      "loss": 1.5746,
      "step": 10
    },
    {
      "epoch": 0.04008016032064128,
      "grad_norm": 0.4802859127521515,
      "learning_rate": 1.9e-05,
      "loss": 1.5592,
      "step": 20
    },
    {
      "epoch": 0.06012024048096192,
      "grad_norm": 0.6747073531150818,
      "learning_rate": 2.9e-05,
      "loss": 1.4625,
      "step": 30
    },
    {
      "epoch": 0.08016032064128256,
      "grad_norm": 1.1916061639785767,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 1.4993,
      "step": 40
    },
    {
      "epoch": 0.10020040080160321,
      "grad_norm": 1.50112783908844,
      "learning_rate": 4.9e-05,
      "loss": 1.4916,
      "step": 50
    },
    {
      "epoch": 0.12024048096192384,
      "grad_norm": 1.3582465648651123,
      "learning_rate": 5.9e-05,
      "loss": 1.1837,
      "step": 60
    },
    {
      "epoch": 0.1402805611222445,
      "grad_norm": 2.17694091796875,
      "learning_rate": 6.9e-05,
      "loss": 1.2919,
      "step": 70
    },
    {
      "epoch": 0.16032064128256512,
      "grad_norm": 2.734104871749878,
      "learning_rate": 7.900000000000001e-05,
      "loss": 1.1729,
      "step": 80
    },
    {
      "epoch": 0.18036072144288579,
      "grad_norm": 2.177248001098633,
      "learning_rate": 8.900000000000001e-05,
      "loss": 1.1175,
      "step": 90
    },
    {
      "epoch": 0.20040080160320642,
      "grad_norm": 2.1697323322296143,
      "learning_rate": 9.900000000000001e-05,
      "loss": 1.1768,
      "step": 100
    },
    {
      "epoch": 0.22044088176352705,
      "grad_norm": 2.495457410812378,
      "learning_rate": 9.997521800752694e-05,
      "loss": 1.2352,
      "step": 110
    },
    {
      "epoch": 0.24048096192384769,
      "grad_norm": 2.2422573566436768,
      "learning_rate": 9.988958339911879e-05,
      "loss": 1.034,
      "step": 120
    },
    {
      "epoch": 0.2605210420841683,
      "grad_norm": 2.361051082611084,
      "learning_rate": 9.974289499706888e-05,
      "loss": 0.9487,
      "step": 130
    },
    {
      "epoch": 0.280561122244489,
      "grad_norm": 2.1555800437927246,
      "learning_rate": 9.95353323154725e-05,
      "loss": 0.9494,
      "step": 140
    },
    {
      "epoch": 0.30060120240480964,
      "grad_norm": 2.3472132682800293,
      "learning_rate": 9.926714936505228e-05,
      "loss": 0.9717,
      "step": 150
    },
    {
      "epoch": 0.32064128256513025,
      "grad_norm": 2.0155727863311768,
      "learning_rate": 9.89386743423053e-05,
      "loss": 0.902,
      "step": 160
    },
    {
      "epoch": 0.3406813627254509,
      "grad_norm": 3.4541542530059814,
      "learning_rate": 9.855030922786335e-05,
      "loss": 1.0213,
      "step": 170
    },
    {
      "epoch": 0.36072144288577157,
      "grad_norm": 1.900282859802246,
      "learning_rate": 9.810252929455777e-05,
      "loss": 1.0792,
      "step": 180
    },
    {
      "epoch": 0.3807615230460922,
      "grad_norm": 1.7474884986877441,
      "learning_rate": 9.759588252579073e-05,
      "loss": 1.0641,
      "step": 190
    },
    {
      "epoch": 0.40080160320641284,
      "grad_norm": 1.8587534427642822,
      "learning_rate": 9.703098894492507e-05,
      "loss": 1.0634,
      "step": 200
    },
    {
      "epoch": 0.42084168336673344,
      "grad_norm": 2.5911948680877686,
      "learning_rate": 9.640853985651305e-05,
      "loss": 1.0044,
      "step": 210
    },
    {
      "epoch": 0.4408817635270541,
      "grad_norm": 2.471625804901123,
      "learning_rate": 9.572929700029292e-05,
      "loss": 1.0813,
      "step": 220
    },
    {
      "epoch": 0.46092184368737477,
      "grad_norm": 2.557529926300049,
      "learning_rate": 9.499409161898808e-05,
      "loss": 0.986,
      "step": 230
    },
    {
      "epoch": 0.48096192384769537,
      "grad_norm": 1.9832371473312378,
      "learning_rate": 9.420382344105036e-05,
      "loss": 1.1226,
      "step": 240
    },
    {
      "epoch": 0.501002004008016,
      "grad_norm": 1.5298187732696533,
      "learning_rate": 9.33594595795918e-05,
      "loss": 0.9573,
      "step": 250
    },
    {
      "epoch": 0.5210420841683366,
      "grad_norm": 1.6246837377548218,
      "learning_rate": 9.246203334885239e-05,
      "loss": 1.0332,
      "step": 260
    },
    {
      "epoch": 0.5410821643286573,
      "grad_norm": 2.2230777740478516,
      "learning_rate": 9.151264299965263e-05,
      "loss": 1.0048,
      "step": 270
    },
    {
      "epoch": 0.561122244488978,
      "grad_norm": 1.4995392560958862,
      "learning_rate": 9.051245037537777e-05,
      "loss": 0.9706,
      "step": 280
    },
    {
      "epoch": 0.5811623246492986,
      "grad_norm": 2.174999713897705,
      "learning_rate": 8.9462679490139e-05,
      "loss": 0.9394,
      "step": 290
    },
    {
      "epoch": 0.6012024048096193,
      "grad_norm": 1.8052353858947754,
      "learning_rate": 8.836461503085162e-05,
      "loss": 1.0055,
      "step": 300
    },
    {
      "epoch": 0.6212424849699398,
      "grad_norm": 2.073298454284668,
      "learning_rate": 8.721960078506268e-05,
      "loss": 1.1176,
      "step": 310
    },
    {
      "epoch": 0.6412825651302605,
      "grad_norm": 1.8714587688446045,
      "learning_rate": 8.60290379964531e-05,
      "loss": 0.9409,
      "step": 320
    },
    {
      "epoch": 0.6613226452905812,
      "grad_norm": 2.315880060195923,
      "learning_rate": 8.479438365002573e-05,
      "loss": 0.9467,
      "step": 330
    },
    {
      "epoch": 0.6813627254509018,
      "grad_norm": 2.2247681617736816,
      "learning_rate": 8.351714868907878e-05,
      "loss": 1.0684,
      "step": 340
    },
    {
      "epoch": 0.7014028056112225,
      "grad_norm": 2.1557302474975586,
      "learning_rate": 8.219889616614596e-05,
      "loss": 1.0849,
      "step": 350
    },
    {
      "epoch": 0.7214428857715431,
      "grad_norm": 1.9473562240600586,
      "learning_rate": 8.08412393301666e-05,
      "loss": 1.1397,
      "step": 360
    },
    {
      "epoch": 0.7414829659318637,
      "grad_norm": 2.233304738998413,
      "learning_rate": 7.94458396522265e-05,
      "loss": 0.9881,
      "step": 370
    },
    {
      "epoch": 0.7615230460921844,
      "grad_norm": 1.6550403833389282,
      "learning_rate": 7.80144047922855e-05,
      "loss": 0.8489,
      "step": 380
    },
    {
      "epoch": 0.781563126252505,
      "grad_norm": 2.33441162109375,
      "learning_rate": 7.654868650938021e-05,
      "loss": 1.1911,
      "step": 390
    },
    {
      "epoch": 0.8016032064128257,
      "grad_norm": 1.8587825298309326,
      "learning_rate": 7.505047851785908e-05,
      "loss": 1.0405,
      "step": 400
    },
    {
      "epoch": 0.8216432865731463,
      "grad_norm": 2.4532430171966553,
      "learning_rate": 7.352161429227359e-05,
      "loss": 0.9201,
      "step": 410
    },
    {
      "epoch": 0.8416833667334669,
      "grad_norm": 7.482452869415283,
      "learning_rate": 7.196396482361175e-05,
      "loss": 0.9676,
      "step": 420
    },
    {
      "epoch": 0.8617234468937875,
      "grad_norm": 2.131842851638794,
      "learning_rate": 7.037943632961976e-05,
      "loss": 0.9088,
      "step": 430
    },
    {
      "epoch": 0.8817635270541082,
      "grad_norm": 2.5273540019989014,
      "learning_rate": 6.876996792201393e-05,
      "loss": 0.9297,
      "step": 440
    },
    {
      "epoch": 0.9018036072144289,
      "grad_norm": 2.1456241607666016,
      "learning_rate": 6.713752923343773e-05,
      "loss": 0.8547,
      "step": 450
    },
    {
      "epoch": 0.9218436873747495,
      "grad_norm": 2.474594831466675,
      "learning_rate": 6.548411800706786e-05,
      "loss": 0.93,
      "step": 460
    },
    {
      "epoch": 0.9418837675350702,
      "grad_norm": 2.5090794563293457,
      "learning_rate": 6.381175765181945e-05,
      "loss": 0.8054,
      "step": 470
    },
    {
      "epoch": 0.9619238476953907,
      "grad_norm": 2.076956033706665,
      "learning_rate": 6.21224947661418e-05,
      "loss": 1.004,
      "step": 480
    },
    {
      "epoch": 0.9819639278557114,
      "grad_norm": 1.8009096384048462,
      "learning_rate": 6.0418396633435646e-05,
      "loss": 0.8836,
      "step": 490
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.7140529751777649,
      "eval_runtime": 0.7472,
      "eval_samples_per_second": 1.338,
      "eval_steps_per_second": 1.338,
      "step": 499
    },
    {
      "epoch": 1.002004008016032,
      "grad_norm": 1.4679436683654785,
      "learning_rate": 5.870154869215629e-05,
      "loss": 0.8664,
      "step": 500
    },
    {
      "epoch": 1.0220440881763526,
      "grad_norm": 1.2510536909103394,
      "learning_rate": 5.697405198369914e-05,
      "loss": 0.9337,
      "step": 510
    },
    {
      "epoch": 1.0420841683366733,
      "grad_norm": 2.170848846435547,
      "learning_rate": 5.5238020581190664e-05,
      "loss": 0.9821,
      "step": 520
    },
    {
      "epoch": 1.062124248496994,
      "grad_norm": 2.2226083278656006,
      "learning_rate": 5.34955790023314e-05,
      "loss": 0.8665,
      "step": 530
    },
    {
      "epoch": 1.0821643286573146,
      "grad_norm": 1.8530402183532715,
      "learning_rate": 5.1748859609457156e-05,
      "loss": 0.8307,
      "step": 540
    },
    {
      "epoch": 1.1022044088176353,
      "grad_norm": 2.2527830600738525,
      "learning_rate": 5e-05,
      "loss": 0.9201,
      "step": 550
    },
    {
      "epoch": 1.122244488977956,
      "grad_norm": 3.27402663230896,
      "learning_rate": 4.8251140390542856e-05,
      "loss": 0.9381,
      "step": 560
    },
    {
      "epoch": 1.1422845691382766,
      "grad_norm": 1.6938259601593018,
      "learning_rate": 4.6504420997668605e-05,
      "loss": 0.9302,
      "step": 570
    },
    {
      "epoch": 1.1623246492985972,
      "grad_norm": 2.565432548522949,
      "learning_rate": 4.476197941880936e-05,
      "loss": 0.8551,
      "step": 580
    },
    {
      "epoch": 1.182364729458918,
      "grad_norm": 1.7601988315582275,
      "learning_rate": 4.3025948016300873e-05,
      "loss": 0.9713,
      "step": 590
    },
    {
      "epoch": 1.2024048096192386,
      "grad_norm": 1.9136714935302734,
      "learning_rate": 4.129845130784371e-05,
      "loss": 0.8657,
      "step": 600
    },
    {
      "epoch": 1.2224448897795592,
      "grad_norm": 2.283865451812744,
      "learning_rate": 3.958160336656436e-05,
      "loss": 0.8379,
      "step": 610
    },
    {
      "epoch": 1.2424849699398797,
      "grad_norm": 2.3849942684173584,
      "learning_rate": 3.7877505233858226e-05,
      "loss": 0.7227,
      "step": 620
    },
    {
      "epoch": 1.2625250501002003,
      "grad_norm": 2.8822078704833984,
      "learning_rate": 3.618824234818057e-05,
      "loss": 0.8919,
      "step": 630
    },
    {
      "epoch": 1.282565130260521,
      "grad_norm": 2.3153469562530518,
      "learning_rate": 3.4515881992932144e-05,
      "loss": 0.7563,
      "step": 640
    },
    {
      "epoch": 1.3026052104208417,
      "grad_norm": 2.6369564533233643,
      "learning_rate": 3.286247076656227e-05,
      "loss": 0.5671,
      "step": 650
    },
    {
      "epoch": 1.3226452905811623,
      "grad_norm": 4.1485466957092285,
      "learning_rate": 3.123003207798607e-05,
      "loss": 0.7831,
      "step": 660
    },
    {
      "epoch": 1.342685370741483,
      "grad_norm": 2.689871072769165,
      "learning_rate": 2.9620563670380263e-05,
      "loss": 0.8605,
      "step": 670
    },
    {
      "epoch": 1.3627254509018036,
      "grad_norm": 2.818765640258789,
      "learning_rate": 2.8036035176388265e-05,
      "loss": 0.9304,
      "step": 680
    },
    {
      "epoch": 1.3827655310621243,
      "grad_norm": 2.6733293533325195,
      "learning_rate": 2.6478385707726422e-05,
      "loss": 0.6851,
      "step": 690
    },
    {
      "epoch": 1.402805611222445,
      "grad_norm": 3.7353882789611816,
      "learning_rate": 2.494952148214093e-05,
      "loss": 0.886,
      "step": 700
    },
    {
      "epoch": 1.4228456913827654,
      "grad_norm": 2.2383601665496826,
      "learning_rate": 2.345131349061978e-05,
      "loss": 0.8257,
      "step": 710
    },
    {
      "epoch": 1.4428857715430863,
      "grad_norm": 3.8822519779205322,
      "learning_rate": 2.1985595207714516e-05,
      "loss": 0.7189,
      "step": 720
    },
    {
      "epoch": 1.4629258517034067,
      "grad_norm": 2.7520835399627686,
      "learning_rate": 2.055416034777353e-05,
      "loss": 0.8136,
      "step": 730
    },
    {
      "epoch": 1.4829659318637274,
      "grad_norm": 3.2273240089416504,
      "learning_rate": 1.9158760669833408e-05,
      "loss": 0.8236,
      "step": 740
    },
    {
      "epoch": 1.503006012024048,
      "grad_norm": 3.200310468673706,
      "learning_rate": 1.7801103833854043e-05,
      "loss": 0.8649,
      "step": 750
    },
    {
      "epoch": 1.5230460921843687,
      "grad_norm": 3.730844259262085,
      "learning_rate": 1.648285131092123e-05,
      "loss": 1.0207,
      "step": 760
    },
    {
      "epoch": 1.5430861723446894,
      "grad_norm": 2.986177682876587,
      "learning_rate": 1.5205616349974272e-05,
      "loss": 0.8964,
      "step": 770
    },
    {
      "epoch": 1.56312625250501,
      "grad_norm": 2.5832910537719727,
      "learning_rate": 1.3970962003546911e-05,
      "loss": 0.87,
      "step": 780
    },
    {
      "epoch": 1.5831663326653307,
      "grad_norm": 3.1344337463378906,
      "learning_rate": 1.2780399214937322e-05,
      "loss": 0.721,
      "step": 790
    },
    {
      "epoch": 1.6032064128256514,
      "grad_norm": 1.8810290098190308,
      "learning_rate": 1.1635384969148395e-05,
      "loss": 0.8969,
      "step": 800
    },
    {
      "epoch": 1.623246492985972,
      "grad_norm": 2.678830623626709,
      "learning_rate": 1.0537320509860998e-05,
      "loss": 0.7894,
      "step": 810
    },
    {
      "epoch": 1.6432865731462925,
      "grad_norm": 2.5479190349578857,
      "learning_rate": 9.487549624622249e-06,
      "loss": 0.8699,
      "step": 820
    },
    {
      "epoch": 1.6633266533066133,
      "grad_norm": 2.0853779315948486,
      "learning_rate": 8.487357000347379e-06,
      "loss": 0.7546,
      "step": 830
    },
    {
      "epoch": 1.6833667334669338,
      "grad_norm": 4.356662273406982,
      "learning_rate": 7.537966651147599e-06,
      "loss": 0.9189,
      "step": 840
    },
    {
      "epoch": 1.7034068136272547,
      "grad_norm": 4.02297830581665,
      "learning_rate": 6.640540420408215e-06,
      "loss": 0.9056,
      "step": 850
    },
    {
      "epoch": 1.723446893787575,
      "grad_norm": 3.1093051433563232,
      "learning_rate": 5.7961765589496454e-06,
      "loss": 0.8349,
      "step": 860
    },
    {
      "epoch": 1.7434869739478958,
      "grad_norm": 3.784414052963257,
      "learning_rate": 5.005908381011926e-06,
      "loss": 0.9909,
      "step": 870
    },
    {
      "epoch": 1.7635270541082164,
      "grad_norm": 2.3527376651763916,
      "learning_rate": 4.270702999707083e-06,
      "loss": 0.7228,
      "step": 880
    },
    {
      "epoch": 1.783567134268537,
      "grad_norm": 2.404806137084961,
      "learning_rate": 3.5914601434869412e-06,
      "loss": 0.7255,
      "step": 890
    },
    {
      "epoch": 1.8036072144288577,
      "grad_norm": 2.5137369632720947,
      "learning_rate": 2.9690110550749495e-06,
      "loss": 0.9322,
      "step": 900
    },
    {
      "epoch": 1.8236472945891784,
      "grad_norm": 3.256601572036743,
      "learning_rate": 2.4041174742092888e-06,
      "loss": 0.721,
      "step": 910
    },
    {
      "epoch": 1.843687374749499,
      "grad_norm": 2.1922824382781982,
      "learning_rate": 1.8974707054422448e-06,
      "loss": 0.6303,
      "step": 920
    },
    {
      "epoch": 1.8637274549098195,
      "grad_norm": 3.2650485038757324,
      "learning_rate": 1.4496907721366582e-06,
      "loss": 0.8013,
      "step": 930
    },
    {
      "epoch": 1.8837675350701404,
      "grad_norm": 2.089212656021118,
      "learning_rate": 1.0613256576947173e-06,
      "loss": 0.9822,
      "step": 940
    },
    {
      "epoch": 1.9038076152304608,
      "grad_norm": 2.5305700302124023,
      "learning_rate": 7.328506349477294e-07,
      "loss": 0.6428,
      "step": 950
    },
    {
      "epoch": 1.9238476953907817,
      "grad_norm": 3.2175869941711426,
      "learning_rate": 4.6466768452750333e-07,
      "loss": 0.9533,
      "step": 960
    },
    {
      "epoch": 1.9438877755511021,
      "grad_norm": 3.1224074363708496,
      "learning_rate": 2.571050029311239e-07,
      "loss": 0.7708,
      "step": 970
    },
    {
      "epoch": 1.9639278557114228,
      "grad_norm": 2.7323415279388428,
      "learning_rate": 1.1041660088121353e-07,
      "loss": 0.7542,
      "step": 980
    },
    {
      "epoch": 1.9839679358717435,
      "grad_norm": 3.530681848526001,
      "learning_rate": 2.478199247306634e-08,
      "loss": 0.9244,
      "step": 990
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7031300663948059,
      "eval_runtime": 0.7408,
      "eval_samples_per_second": 1.35,
      "eval_steps_per_second": 1.35,
      "step": 998
    },
    {
      "epoch": 2.0,
      "step": 998,
      "total_flos": 8.814675956504986e+16,
      "train_loss": 0.9522180471248283,
      "train_runtime": 2340.2375,
      "train_samples_per_second": 0.426,
      "train_steps_per_second": 0.426
    }
  ],
  "logging_steps": 10,
  "max_steps": 998,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.814675956504986e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
